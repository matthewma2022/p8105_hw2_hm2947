---
title: "HW2"
author: "Matthew Ma"
date: "2022-10-3"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r load_libraries}
library(tidyverse)
library(readxl)
library(lubridate)
```


## Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations. There are 465 distinct stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. There are 84 stations that are ADA compliant.

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this). The proportion is 0.377.

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows). There are 60 stations that serve the A train, and 17 of them are ADA compliant.

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

## Problem 2

```{r}
mr_trash_df = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range="A2:N550") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(sports_balls)) 

 mr_trash_df = mutate(mr_trash_df, mrdf = grocery_bags - glass_bottles)
```

```{r}
prof_trash_df = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range="A2:M97") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) 

prof_trash_df = mutate(prof_trash_df, profdf = grocery_bags - glass_bottles )
  
```

## Combine the two dataset

```{r}
trash_wheel =
  full_join(mr_trash_df, prof_trash_df, by = "weight_tons") 

total_weight_pf = sum(prof_trash_df$weight_tons)

total_sb_mr = filter(mr_trash_df, year == "2020") %>% select(sports_balls) %>% sum()

```

* There are a total number of `r nrow(trash_wheel)` observations in the dataset. There are a total number of `r ncol(trash_wheel)` variables in the dataset. The key variables' names are `r names(trash_wheel)`
* The total weight of trash collected by Professor Trash Wheel is `r total_weight_pf`
* The total number of sports balls collected by Mr. Trash Wheel is `r total_sb_mr`

## Problem 3

```{r}
pols_df = 
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names()

pols_df = 
  separate(pols_df, col = mon, into = c('year', 'month', 'day'), sep = '-')
pols_df <- pols_df %>% mutate(month = month.abb[as.numeric(month)])
  
pols_df <- pols_df %>% mutate( president = ifelse(prez_gop == "0", "dem","gop")) 

pols_df <- subset(pols_df, select = -day)
pols_df <- subset(pols_df, select = -prez_dem)
pols_df <- subset(pols_df, select = -prez_gop)
```


```{r}
snp_df =
  read_csv("data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(date = lubridate::parse_date_time2(date,orders ="mdy", cutoff_2000 = 23))

snp_df = 
  separate(snp_df, col = date, into = c('year', 'month', 'day'), sep = '-')
snp_df <- snp_df %>% mutate(month = month.abb[as.numeric(month)])
snp_df <- subset(snp_df, select = -day)

snp_df <- snp_df %>% 
  select(year, month, everything())
```


## Tidy the unemployment data

```{r}
unemp_df = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% pivot_longer(jan:dec,
    names_to = "month",
    values_to = "unemployment_rate") %>% 
  mutate(month = str_to_title(month)) %>% 
  mutate(year = as.character(year))

#somehow the "year" variable in this dataset is incompatible with the other two as being "double" type variable so I changed it to "character".
```

## Merging the datasets

```{r}
fte_df = 
  left_join(pols_df, snp_df, by = c("year", "month")) 
  
five_thirty_eight = 
  left_join(fte_df, unemp_df, by = c("year", "month"))
```

* The dataset ` pols_df ` contains `r nrow(pols_df)` observations and `r ncol(pols_df)` with the names `r names(pols_df)`. The year ranges from `r pols_df %>% pull(year) %>% range()`.

* The dataset ` snp_df ` contains `r nrow(snp_df)` observations and `r ncol(snp_df)` with the names `r names(snp_df)`. The year ranges from `r snp_df %>% pull(year) %>% range()`.

* The dataset ` unemp_df ` contains `r nrow(unemp_df)` observations and `r ncol(unemp_df)` with the names `r names(unemp_df)`. The year ranges from `r unemp_df %>% pull(year) %>% range()`.

* The merged dataset ` fte_df ` between `pols_df` and `snp_df` contains `r nrow(fte_df)` observations and `r ncol(fte_df)` with the names `r names(fte_df)`. The year ranges from `r fte_df %>% pull(year) %>% range()`.

* The merged dataset `five_thirty_eight ` between the resulting merged dataset `fte_df` and `unemp_df` contains `r nrow(five_thirty_eight)` observations and `r ncol(five_thirty_eight)` with the names `r names(five_thirty_eight)`. The year ranges from `r five_thirty_eight %>% pull(year) %>% range()`.
